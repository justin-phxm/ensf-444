{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "CNDKREiQRJJX",
      "metadata": {
        "id": "CNDKREiQRJJX"
      },
      "source": [
        "<font size=\"+3\"><b>Assignment 3: Non-Linear Models and Validation Metrics</b></font>\n",
        "\n",
        "***\n",
        "* **Full Name** =\n",
        "* **UCID** =\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='Blue'>\n",
        "In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.\n",
        "</font>\n",
        "\n",
        "|                **Question**                | **Point** |\n",
        "|:------------------------------------------:|:---------:|\n",
        "|           **Part 1: Regression**           |  **14.5** |\n",
        "|          Step 0: Import Libraries          |           |\n",
        "|             Step 1: Data Input             |    0.5    |\n",
        "|           Step 2: Data Processing          |     0     |\n",
        "| Step 3: Implement   Machine Learning Model |    0.5    |\n",
        "|           Step 4: Validate Model           |    0.5    |\n",
        "|         Step 5: Visualize   Results        |     3     |\n",
        "|                  Questions                 |     6     |\n",
        "|             Process Description            |     4     |\n",
        "|         **Part 2: Classification**         |  **17.5** |\n",
        "|             Step 1: Data Input             |     2     |\n",
        "|           Step 2: Data Processing          |    1.5    |\n",
        "| Step 3: Implement   Machine Learning Model |           |\n",
        "|            Step 4: Validate Mode           |           |\n",
        "|         Step 5: Visualize   Results        |     4     |\n",
        "|                  Questions                 |     6     |\n",
        "|             Process Description            |     4     |\n",
        "|   **Part 3: Observations/Interpretation**  |   **3**   |\n",
        "|           **Part 4: Reflection**           |   **2**   |\n",
        "|                  **Total**                 |   **37**  |\n",
        "|                                            |           |\n",
        "|                  **Bonus**                 |           |\n",
        "|         **Part 5: Bonus Question**         |   **3**   |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf275ca7",
      "metadata": {
        "id": "cf275ca7"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b67a661",
      "metadata": {
        "id": "2b67a661"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee2d2c3",
      "metadata": {
        "id": "5ee2d2c3"
      },
      "source": [
        "# **Part 1: Regression (14.5 marks)**\n",
        "\n",
        "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8219f163",
      "metadata": {
        "id": "8219f163"
      },
      "source": [
        "## **Step 1:** Data Input (0.5 marks)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2af8bd32",
      "metadata": {
        "id": "2af8bd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X.shape: (1030, 8), Y.shape: y.shape\n",
            "type(x): <class 'pandas.core.frame.DataFrame'> \n",
            "types(y): <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Import concrete dataset from yellowbrick library\n",
        "from yellowbrick.datasets.loaders import load_concrete\n",
        "\n",
        "# Load the spam dataset\n",
        "data = load_concrete(return_dataset=True)\n",
        "\n",
        "# TO DO: Print size and type of X and y\n",
        "X, y = data.to_data()\n",
        "print(f\"X.shape: {X.shape}, Y.shape: y.shape\")\n",
        "print(f\"type(x): {type(X)} \\ntypes(y): {type(y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fea4cc",
      "metadata": {
        "id": "42fea4cc"
      },
      "source": [
        "## **Step 2:** Data Processing (0 marks)\n",
        "\n",
        "Data processing was completed in the previous assignment. No need to repeat here.\n",
        "\n",
        "<font color='red'>\n",
        "This is just for your information and no action is required from you for this step.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model (0.5 marks)\n",
        "\n",
        "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
        "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
        "3. Implement each machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f994e31",
      "metadata": {
        "id": "3f994e31"
      },
      "source": [
        "## **Step 4:** Validate Model (0.5 marks)\n",
        "\n",
        "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc3f7a8",
      "metadata": {
        "id": "5fc3f7a8"
      },
      "source": [
        "## **Step 5:** Visualize Results (3 marks)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fdc93a78",
      "metadata": {
        "id": "fdc93a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'DecisionTreeRegressor': {'train': 47.91856102734339, 'test': 163.08777547307804}, 'RandomForestRegressor': {'train': 32.05543206759723, 'test': 156.40497179627897}, 'GradientBoostingRegressor': {'train': 3.739270010942101, 'test': 99.3602591572192}}\n",
            "   Training Accuracy Validation Accuracy\n",
            "DT         47.918561          163.087775\n",
            "RF         32.055432          156.404972\n",
            "GB           3.73927           99.360259\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Import Decision tree, random forest, and gradient boosting from sklearn\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "# 2. Instantiate the models with parameters\n",
        "max_depth = 5\n",
        "n_estimators = 100\n",
        "learning_rate = 0.1\n",
        "random_state = 0\n",
        "\n",
        "dt = DecisionTreeRegressor(max_depth=max_depth, random_state=random_state)\n",
        "rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
        "gb = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=random_state)\n",
        "\n",
        "# 3. Implement each model with X and y\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Calculate average training and validation accuracy with MSE cross-validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn import metrics\n",
        "\n",
        "scoring=\"neg_mean_squared_error\"\n",
        "\n",
        "accuracies = {}\n",
        "models = [dt, rf, gb]\n",
        "\n",
        "# Perform cross-validation for each model\n",
        "for model in models:\n",
        "    cv_results = cross_validate(model, X, y, cv=5, scoring=scoring, return_train_score=True)\n",
        "    accuracies[model.__class__.__name__] = {\n",
        "        \"train\": -1 * cv_results[\"train_score\"].mean(),\n",
        "        \"test\": -1 * cv_results[\"test_score\"].mean()\n",
        "    }\n",
        "\n",
        "# 1. Create a pandas dataframe with the accuracies\n",
        "results = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\"], index=[\"DT\", \"RF\", \"GB\"])\n",
        "\n",
        "# 2. Add the accuracies to the dataframe\n",
        "for index, (k, v) in enumerate(accuracies.items()):\n",
        "    results.iloc[index] = [v[\"train\"], v[\"test\"]]\n",
        "\n",
        "# 3. Print the results\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31715a9d",
      "metadata": {
        "id": "31715a9d"
      },
      "source": [
        "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`.\n",
        "\n",
        "<font color='red'>\n",
        "Due to the similarity of this to the main part of step 5, this part is 0.5 and the main part of step 5 is 2.5 of the total 3 points for this step.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83539f47",
      "metadata": {
        "id": "83539f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Training R2 Validation R2\n",
            "DT    0.822887       0.17621\n",
            "RF    0.881221      0.173748\n",
            "GB    0.986436      0.473701\n"
          ]
        }
      ],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# This would be similar to the main step, the main difference is the scoring.\n",
        "\n",
        "scoring=\"r2\"\n",
        "\n",
        "accuracies = {}\n",
        "models = [dt, rf, gb]\n",
        "\n",
        "# Perform cross-validation for each model\n",
        "for model in models:\n",
        "    cv_results = cross_validate(model, X, y, cv=5, scoring=scoring, return_train_score=True)\n",
        "    accuracies[model.__class__.__name__] = {\n",
        "        \"train\": cv_results[\"train_score\"].mean(),\n",
        "        \"test\": cv_results[\"test_score\"].mean()\n",
        "    }\n",
        "\n",
        "# 1. Create a pandas dataframe with the accuracies\n",
        "results = pd.DataFrame(columns=[\"Training R2\", \"Validation R2\"], index=[\"DT\", \"RF\", \"GB\"])\n",
        "\n",
        "# 2. Add the accuracies to the dataframe\n",
        "for index, (k, v) in enumerate(accuracies.items()):\n",
        "    results.iloc[index] = [v[\"train\"], v[\"test\"]]\n",
        "\n",
        "# 3. Print the results\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "af22a4de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Training Accuracy Validation Accuracy Training R2 Validation R2\n",
            "DT         47.918561          163.087775    0.822887       0.17621\n",
            "RF         32.055432          156.404972    0.881221      0.173748\n",
            "GB           3.73927           99.360259    0.986436      0.473701\n"
          ]
        }
      ],
      "source": [
        "accuracies = {}\n",
        "models = [dt, rf, gb]\n",
        "for model in models:\n",
        "    cv_results = cross_validate(model, X, y, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)\n",
        "    cv_results1 = cross_validate(model, X, y, cv=5, scoring=\"r2\", return_train_score=True)\n",
        "    \n",
        "    accuracies[model.__class__.__name__] = {\n",
        "        \"trainMSE\": -1 * cv_results[\"train_score\"].mean(),\n",
        "        \"testMSE\": -1 * cv_results[\"test_score\"].mean(),\n",
        "        \"trainR2\": cv_results1[\"train_score\"].mean(),\n",
        "        \"testR2\": cv_results1[\"test_score\"].mean(),\n",
        "    }\n",
        "\n",
        "results = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\", \"Training R2\", \"Validation R2\"], index=[\"DT\", \"RF\", \"GB\"])\n",
        "for index, (k, v) in enumerate(accuracies.items()):\n",
        "    results.iloc[index] = [v[\"trainMSE\"], v[\"testMSE\"], v[\"trainR2\"], v[\"testR2\"]]\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5257a98",
      "metadata": {
        "id": "a5257a98"
      },
      "source": [
        "## Questions (6 marks)\n",
        "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
        "1. Out of the models you tested, which model would you select for this dataset and why?\n",
        "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2PRnpiFjVDzv",
      "metadata": {
        "id": "2PRnpiFjVDzv"
      },
      "source": [
        "<font color='Green'><b>\n",
        "\n",
        "1. Comparing the results of DT, RF, and GB to the linear models of assignment 2, we can see that the R2 Training scores for the linear model `(0.61)` was outperformed by the tree based models `(0.82, 0.88, 0.99)` in this assignment. However, when it comes to new and unseen data, these scores change dramatically. The linear model outperformed all the tree based models from `(0.64)` to `(0.18, 0.17, 0.47)` respectively. This could be due to the tree based models overfitting the data.\n",
        "\n",
        "Linear Model results\n",
        "```\n",
        "     Training Accuracy  Validation Accuracy\n",
        "MSE         110.345501            95.635335\n",
        "R2            0.609071             0.636898\n",
        "```\n",
        "\n",
        "Tree Based Model results\n",
        "```\n",
        "   Training Accuracy Validation Accuracy Training R2 Validation R2\n",
        "DT         47.918561          163.087775    0.822887       0.17621\n",
        "RF         32.055432          156.404972    0.881221      0.173748\n",
        "GB           3.73927           99.360259    0.986436      0.473701\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "1. From the models created in this assignment, DT, RF, and GB, I would choose the GB model because of it's high scores. We can see that GB outperformed DT and RF in both accuracy and R2 in all scenarios. What was especially impressive was the Validation R2 score where GB received a score of `(0.47)` compared to DT and RF's scores of `(0.18, 0.17)` respectively.\n",
        "\n",
        "1. To increase the accuracy of the tree-based models, there are a few options and parameters we can tune. The first option could be to increase the size of the data set. With more data, the models will get closer to the true value of the data.\n",
        "The second option could be to increase the max_depth of the trees. In this assignment, we set max_depth = 5, meaning that the trees would have a total depth of 5. By increasing this value closer, overfitting is increased, but we may see higher accuracy scores.\n",
        "\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b238f4",
      "metadata": {
        "id": "37b238f4"
      },
      "source": [
        "## Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93097bfe",
      "metadata": {
        "id": "93097bfe"
      },
      "source": [
        "<font color='Green'><b>\n",
        "\n",
        "1. Where did you source your code?\n",
        "All the code generated in this assignment was done personally, from the previous assignments and labs,  and through github copilot.\n",
        "1. In what order did you complete the steps?\n",
        "I completed the steps from top to bottom in order.\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "I did not need to use any prompts as copilot automatically suggested code based on the entire repository.\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
        "One of the challenges I had was with cross_validation(). I was not familiar with the use of this function and did not see it being used in previous labs and assignments. Reading the documentation helped me become successful and overcome this challenge\n",
        "\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "# **Part 2: Classification (17.5 marks)**\n",
        "\n",
        "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "## **Step 1:** Data Input (2 marks)\n",
        "\n",
        "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
        "\n",
        "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset\n",
        "\n",
        "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
        "\n",
        "Print the size and type of `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67"
      },
      "outputs": [],
      "source": [
        "# TO DO: Import wine dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "## **Step 2:** Data Processing (1.5 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28af110",
      "metadata": {
        "id": "a28af110"
      },
      "source": [
        "Print the first five rows of the dataset to inspect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ea266921",
      "metadata": {
        "id": "ea266921"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834fc8fe",
      "metadata": {
        "id": "834fc8fe"
      },
      "source": [
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "97c6e9dc",
      "metadata": {
        "id": "97c6e9dc"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070956af",
      "metadata": {
        "id": "070956af"
      },
      "source": [
        "How many samples do we have of each type of wine?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b37a6fd9",
      "metadata": {
        "id": "b37a6fd9"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
        "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0870b0d2",
      "metadata": {
        "id": "0870b0d2"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0bbd83",
      "metadata": {
        "id": "bb0bbd83"
      },
      "source": [
        "## **Step 5:** Visualize Results (4 marks)\n",
        "\n",
        "<font color='red'>\n",
        "There is no individual mark for Steps 3 and 4 and those grades are included within the four points.\n",
        "\n",
        "</font>\n",
        "\n",
        "### **Step 5.1:** Compare Models (2 out of total 4 marks)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e17878",
      "metadata": {
        "id": "f2e17878"
      },
      "source": [
        "### **Step 5.2:** Visualize Classification Errors  (2 out of total 4 marks)\n",
        "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "44b091a4",
      "metadata": {
        "id": "44b091a4"
      },
      "outputs": [],
      "source": [
        "# TO DO: Implement best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "09d21b59",
      "metadata": {
        "id": "09d21b59"
      },
      "outputs": [],
      "source": [
        "# TO DO: Print confusion matrix using a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5ef95947",
      "metadata": {
        "id": "5ef95947"
      },
      "outputs": [],
      "source": [
        "# TO DO: Print classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf319621",
      "metadata": {
        "id": "bf319621"
      },
      "source": [
        "## Questions (6 marks)\n",
        "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
        "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
        "1. How many samples were incorrectly classified in step 5.2?\n",
        "1. In this case, is maximizing precision or recall more important? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1FQstcwnXXng",
      "metadata": {
        "id": "1FQstcwnXXng"
      },
      "source": [
        "\n",
        "<font color='Green'><b>YOUR ANSWERS HERE</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "664ff8ae",
      "metadata": {
        "id": "664ff8ae"
      },
      "source": [
        "## Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e837da",
      "metadata": {
        "id": "d0e837da"
      },
      "source": [
        "<font color='Green'><b>DESCRIBE YOUR PROCESS HERE</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd7358d",
      "metadata": {
        "id": "4cd7358d"
      },
      "source": [
        "# **Part 3: Observations/Interpretation (3 marks)**\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F3ifv218XL62",
      "metadata": {
        "id": "F3ifv218XL62"
      },
      "source": [
        "<font color='Green'><b>\n",
        "ADD YOUR FINDINGS HERE\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd97b6ac",
      "metadata": {
        "id": "cd97b6ac"
      },
      "source": [
        "## **Part 4:** Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tDFYc89YXQGJ",
      "metadata": {
        "id": "tDFYc89YXQGJ"
      },
      "source": [
        "<font color='Green'><b>\n",
        "ADD YOUR THOUGHTS HERE\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa21e53b",
      "metadata": {
        "id": "fa21e53b"
      },
      "source": [
        "## **Part 5:** Bonus Question (3 marks)\n",
        "\n",
        "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
        "\n",
        "Is `LinearSVC` a good fit for this dataset? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "30fea72e",
      "metadata": {
        "id": "30fea72e"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabc68a4",
      "metadata": {
        "id": "aabc68a4"
      },
      "source": [
        "*ANSWER HERE*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241c3b12",
      "metadata": {
        "id": "241c3b12"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
